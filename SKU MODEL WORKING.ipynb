{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'SKU110K_CVPR19' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/eg4000/SKU110K_CVPR19.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('SKU110K_CVPR19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import keras_retinanet\n",
    "from object_detector_retinanet.keras_retinanet import models\n",
    "from object_detector_retinanet.keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from object_detector_retinanet.keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from object_detector_retinanet.keras_retinanet.utils.colors import label_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import for EM Merger and viz\n",
    "from object_detector_retinanet.keras_retinanet.utils import EmMerger\n",
    "from object_detector_retinanet.utils import create_folder, root_dir\n",
    "\n",
    "\n",
    "# import miscellaneous modules\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "# set tf backend to allow memory to grow, instead of claiming everything\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vicky/anaconda3/envs/sku/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vicky/anaconda3/envs/sku/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vicky/anaconda3/envs/sku/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vicky/anaconda3/envs/sku/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2139: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vicky/anaconda3/envs/sku/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vicky/anaconda3/envs/sku/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vicky/Notebooks/SKU110K_CVPR19/object_detector_retinanet/keras_retinanet/backend/tensorflow_backend.py:56: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vicky/anaconda3/envs/sku/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vicky/anaconda3/envs/sku/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vicky/anaconda3/envs/sku/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vicky/anaconda3/envs/sku/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vicky/anaconda3/envs/sku/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vicky/anaconda3/envs/sku/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vicky/anaconda3/envs/sku/lib/python3.6/site-packages/keras/engine/saving.py:310: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vicky/Notebooks/SKU110K_CVPR19/object_detector_retinanet/keras_retinanet/backend/tensorflow_backend.py:92: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model_path = '/home/vicky/Downloads/iou_resnet50_csv_06.h5'\n",
    "model = models.load_model(model_path, backbone_name='resnet50',convert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path=\"/home/vicky/Documents/SKU110K/images/IMG-20201008-WA0009.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(image_path,output_path):\n",
    "    image = read_image_bgr(image_path)\n",
    "\n",
    "    # for filtering predictions based on score (objectness/confidence)\n",
    "    threshold = 0.3\n",
    "\n",
    "    # copy to draw on\n",
    "    draw = image.copy()\n",
    "    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # preprocess image for network\n",
    "    image = preprocess_image(image)\n",
    "    image, scale = resize_image(image)\n",
    "\n",
    "    # Run inference\n",
    "    boxes, hard_scores, labels, soft_scores = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "    hard_score_rate=.3\n",
    "    max_detections = 9999\n",
    "\n",
    "    soft_scores = np.squeeze(soft_scores, axis=-1)\n",
    "    soft_scores = hard_score_rate * hard_scores + (1 - hard_score_rate) * soft_scores\n",
    "\n",
    "    # correct boxes for image scale\n",
    "    boxes /= scale\n",
    "\n",
    "    # select indices which have a score above the threshold\n",
    "    indices = np.where(hard_scores[0, :] > threshold)[0]\n",
    "\n",
    "    # select those scores\n",
    "    scores = soft_scores[0][indices]\n",
    "    hard_scores = hard_scores[0][indices]\n",
    "\n",
    "    # find the order with which to sort the scores\n",
    "    scores_sort = np.argsort(-scores)[:max_detections]\n",
    "\n",
    "    # select detections\n",
    "    image_boxes = boxes[0, indices[scores_sort], :]\n",
    "    image_scores = scores[scores_sort]\n",
    "    image_hard_scores = hard_scores[scores_sort]\n",
    "    image_labels = labels[0, indices[scores_sort]]\n",
    "    image_detections = np.concatenate(\n",
    "        [image_boxes, np.expand_dims(image_scores, axis=1), np.expand_dims(image_labels, axis=1)], axis=1)\n",
    "    results = np.concatenate(\n",
    "        [image_boxes, np.expand_dims(image_scores, axis=1), np.expand_dims(image_hard_scores, axis=1),\n",
    "         np.expand_dims(image_labels, axis=1)], axis=1)\n",
    "    filtered_data = EmMerger.merge_detections(image_path, results)\n",
    "    filtered_boxes = []\n",
    "    filtered_scores = []\n",
    "    filtered_labels = []\n",
    "    \n",
    "    csv_data_lst = []\n",
    "    csv_data_lst.append(['image_id', 'x1', 'y1', 'x2', 'y2', 'confidence', 'hard_score'])\n",
    "    \n",
    "    for ind, detection in filtered_data.iterrows():\n",
    "        box = np.asarray([detection['x1'], detection['y1'], detection['x2'], detection['y2']])\n",
    "        filtered_boxes.append(box)\n",
    "        filtered_scores.append(detection['confidence'])\n",
    "        filtered_labels.append('{0:.2f}'.format(detection['hard_score']))\n",
    "        row = [image_path, detection['x1'], detection['y1'], detection['x2'], detection['y2'],\n",
    "               detection['confidence'], detection['hard_score']]\n",
    "        csv_data_lst.append(row)\n",
    "    print(csv_data_lst)\n",
    "    labels_to_names = {0: 'object'}\n",
    "    for box, score, label in zip(filtered_boxes, filtered_scores, filtered_labels):\n",
    "        # scores are sorted so we can break\n",
    "        if score < threshold:\n",
    "            break\n",
    "\n",
    "        color = [31, 0, 255]#label_color(label) ## BUG HERE LABELS ARE FLOATS SO COLOR IS HARDCODED \n",
    "\n",
    "        b = box.astype(int)\n",
    "        draw_box(draw, b, color=color)\n",
    "\n",
    "        caption = \"{} {:.3f}\".format(labels_to_names[0], score)\n",
    "        draw_caption(draw, b, caption)\n",
    "    detected_img =cv2.cvtColor(draw, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#     cv2.imwrite(output_path,detected_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 20))\n",
    "# plt.axis('off')\n",
    "# plt.imshow(draw)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/home/vicky/Downloads/HUL SAMPLES'\n",
    "output='/home/vicky/Documents/SKU110K_Output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hair_GT (7).jpeg\n",
      "[['image_id', 'x1', 'y1', 'x2', 'y2', 'confidence', 'hard_score'], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 891, 725, 950, 889, 0.7985255718231201, 0.7158021926879883], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 847, 730, 886, 860, 0.7296908497810364, 0.5288412570953369], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 353, 727, 424, 895, 0.7822343707084656, 0.648598313331604], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 678, 714, 731, 907, 0.6939334869384766, 0.41353335976600647], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 429, 718, 505, 895, 0.799734890460968, 0.7152411341667175], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 263, 707, 326, 894, 0.6777764558792114, 0.38792943954467773], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 162, 707, 257, 912, 0.8432467579841614, 0.8275237083435059], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 552, 703, 612, 889, 0.8336702585220337, 0.8248674869537354], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 618, 699, 682, 896, 0.7998619079589844, 0.7183405160903931], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 791, 715, 842, 871, 0.7619873881340027, 0.668606698513031], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 1045, 703, 1107, 869, 0.7938044667243958, 0.7050576210021973], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 735, 693, 784, 890, 0.7360053658485413, 0.5737366080284119], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 957, 691, 1041, 883, 0.8332532048225403, 0.7499780058860779], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 1189, 702, 1244, 830, 0.6746842861175537, 0.4821431338787079], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 1112, 698, 1168, 853, 0.7643241286277771, 0.640475332736969], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 302, 537, 350, 672, 0.7204217314720154, 0.5064685344696045], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 766, 292, 831, 529, 0.8156471848487854, 0.747519850730896], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 559, 296, 645, 528, 0.8274290561676025, 0.7648206949234009], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 955, 289, 1034, 534, 0.8340910077095032, 0.7725929617881775], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 141, 268, 228, 533, 0.833715558052063, 0.7679832577705383], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 352, 281, 437, 531, 0.8706167936325073, 0.862980306148529], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 54, 266, 133, 528, 0.8360422253608704, 0.7521605491638184], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 1043, 251, 1130, 532, 0.8402848839759827, 0.815717339515686], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 657, 251, 765, 539, 0.8352274298667908, 0.7971864938735962], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 852, 238, 945, 534, 0.8336023092269897, 0.7824312448501587], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 1135, 246, 1215, 533, 0.7895736694335938, 0.6839746832847595], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 446, 230, 550, 532, 0.8697493076324463, 0.8555501699447632], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 236, 222, 339, 529, 0.8446524739265442, 0.7954972982406616], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 1005, 1, 1099, 75, 0.7051486372947693, 0.34962034225463867], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 884, 1, 991, 75, 0.7473130822181702, 0.40339574217796326], ['/home/vicky/Downloads/HUL SAMPLES/Hair_GT (7).jpeg', 756, 1, 867, 71, 0.7152132987976074, 0.38110867142677307]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vicky/Notebooks/SKU110K_CVPR19/object_detector_retinanet/keras_retinanet/utils/EmMerger.py:81: FutureWarning: 'argmax' is deprecated, use 'idxmax' instead. The behavior of 'argmax'\n",
      "will be corrected to return the positional maximum in the future.\n",
      "Use 'series.values.argmax' to get the position of the maximum now.\n",
      "  best_detection_id = original_detections.avg_score.argmax()\n",
      "/home/vicky/Notebooks/SKU110K_CVPR19/object_detector_retinanet/keras_retinanet/utils/Boxes.py:148: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  image_boxes = image_data.as_matrix(BOX_CONSTANTS)\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(path):\n",
    "    input_path=os.path.join(path,file)\n",
    "    output_path=os.path.join(output,file)\n",
    "    print(file)\n",
    "    get_prediction(input_path,output_path)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
